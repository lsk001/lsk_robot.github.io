---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

My research sits at the intersection of robotics, control theory, and machine learning, with a focus on ensuring **trustworthy, transparent, and explainable robot motion behavior generation** through a combination of data-driven learning and model-based optimal control. My research interests span the fields of robot motion control, reinforcement learning, and autonomous behavior generation in open world, with applications to legged robot locomotion, human-robot interaction and embodied AI.

My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>).


# üî• News
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìù Selected Publications 

<div class='paper-box'>
  <div class='paper-box-image'>
    <div>
      <div class="badge">RAL2025</div>
      <!-- ÊõøÊç¢ÂõæÁâá‰∏∫ËßÜÈ¢ë -->
      <video width="100%" controls poster="images/algorithm_frame.jpg">
        <source src="images/RAL2025.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </div>
  </div>
<div class='paper-box-text' markdown="1">

[Koopman-based Robust Learning Control with Extended State Observer] 

**Shangke Lyu‚Ä†**, Xin Lang‚Ä†, Donglin Wang,
IEEE Robotics and Automation Letters, vol. 10, no. 3, pp. 2303-2310, 2025.

- In this paper, we propose a robust active learning (RAL) control method designed to optimize data efficiency during model learning while ensuring robust and precise control during task execution.  
</div>
</div>

<div class='paper-box'>
  <div class='paper-box-image'>
    <div>
      <div class="badge">RSS2024</div>
      <!-- ÊõøÊç¢ÂõæÁâá‰∏∫ËßÜÈ¢ë -->
      <video width="100%" controls poster="images/RSS2024_c.jpg">
        <source src="images/RSS2024_v.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </div>
  </div>
<div class='paper-box-text' markdown="1">

[RL2AC: Reinforcement Learning-based Rapid Online Adaptive Control for Legged Robot Robust Locomotion] 

**Shangke Lyu**, Xin Lang, Han Zhao, Hongyin Zhang, Pengxiang Ding, Donglin Wang,
Robotics: Science and Systems(RSS), 2024.

- In this paper, we seek to ascertain the control mechanism behind the locomotion RL policy, from which we propose a new RL based Rapid onLine Adaptive Control (RL2AC) algorithm to complementarily combine the RL policy and the adaptive control together.
</div>
</div>


<div class='paper-box'>
  <div class='paper-box-image'>
    <div>
      <div class="badge">CEP2024</div>
      <!-- ÊõøÊç¢ÂõæÁâá‰∏∫ËßÜÈ¢ë -->
      <video width="100%" controls poster="images/CEP2024_c.jpg">
        <source src="images/CEP2024_v.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </div>
  </div>
<div class='paper-box-text' markdown="1">

[A Coordinated Framework of Aerial Manipulator for Safe and Compliant Physical Interaction] 

Qianyuan Liu, **Shangke Lyu^**, Kexin Guo, Jianliang Wang, Xiang Yu, Lei Guo,
Control Engineering Practice, vol.146, 2024.

- This paper proposes a coordinated interactive framework for aerial manipulators to achieve safe and compliant interaction when physically contacting the surroundings.
</div>
</div>

<div class='paper-box'>
  <div class='paper-box-image'>
    <div>
      <div class="badge">IEEE-TCST2020</div>
      <!-- ÊõøÊç¢ÂõæÁâá‰∏∫ËßÜÈ¢ë -->
      <video width="100%" controls poster="images/TCST2020.jpg">
        <source src="images/TCST2020_v.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </div>
  </div>
<div class='paper-box-text' markdown="1">

[Human-Robot Interaction Control Based on a General Energy Shaping Method] 

**Shangke Lyu**, Chien Chern Cheah,
IEEE Transactions on Control Systems Technology, vol. 28, no. 6, pp. 2445-2460, 2020.

- In this article, a general HRI control framework is proposed for the scenario of the human and robot coexisting in the same workspace.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Automatica2020</div><img src='images/Auto2020.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Data-driven Learning for Robot Control With Unknown Jacobian]

**Shangke Lyu**, Chien Chern Cheah,
Automatica, vol. 120, pp.109-120, 2020.

- In this paper, a NN based data driven offline learning algorithm and an online learning controller are proposed, which are combined in a complementary way.
</div>
</div>

# üéñ Honors and Awards
- *07/2018* **Best Paper Award Finalists**, by The 2018 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM).
- *06/2016* **Best Conference Paper Award**, by The 2016 IEEE International Conference on Real-time Computing and Robotics (RCAR).

# üìñ Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
